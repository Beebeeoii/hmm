{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading of Data\n",
    "Here, we load a corpus from a sub-Reddit via a text file. Each line represents a new post or comment of a post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a dataframe\n",
    "df = pd.read_csv(\"../data/AskReddit_processed.txt\", sep='\\t', names=['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: (12859, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is your creepy/paranormal experience that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is something you have witnessed but no on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what movies do you think have the craziest bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is something you do that you know is bad ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for me it's smelling sharpies lol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  What is your creepy/paranormal experience that...\n",
       "1  What is something you have witnessed but no on...\n",
       "2  what movies do you think have the craziest bac...\n",
       "3  What is something you do that you know is bad ...\n",
       "4                  for me it's smelling sharpies lol"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the dataframe\n",
    "print(f\"Dimension: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "Before we can perform Part-of-Speech (POS) tagging via Hidden Markov Model (HMM) and running Viterbi algorithm,\n",
    "we will first require an annotated dataset. This can be achieved via the corpus which we loaded before this,\n",
    "before we can use it to create a HMM model to perform POS tagging via Viterbi algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotating the Dataset\n",
    "\n",
    "Annotating the dataset refer to assigning each word its corresponding POS tag in the corpus that is used to train\n",
    "our HMM model. For the purpose of this demonstration of POS tagging via HMM and Viterbi, we will make use of SpaCy\n",
    "to annotate our dataset.\n",
    "\n",
    "However, do note that in practice, annotation might be better done by experts who are able\n",
    "to accurately tag each word in the corpus with its correct POS tag.\n",
    "\n",
    "> Note: Install en_core_web_sm first before running this cell by running:\n",
    "> `python -m spacy download en_core_web_sm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Install en_core_web_sm first before running this cell\n",
    "#       by doing: python -m spacy download en_core_web_lg\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def pos_tag(sentence):\n",
    "    # Process the sentence using the spaCy NLP pipeline\n",
    "    doc = nlp(sentence)\n",
    "    # Extract tokens and their POS tags\n",
    "    tagged_tokens = [(token.text.lower(), token.pos_) for token in doc]\n",
    "    return tagged_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we annotate our corpus using SpaCy by applying the function `pos_tag` which we wrote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>POS_Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is your creepy/paranormal experience that...</td>\n",
       "      <td>[(what, PRON), (is, AUX), (your, PRON), (creep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is something you have witnessed but no on...</td>\n",
       "      <td>[(what, PRON), (is, AUX), (something, PRON), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what movies do you think have the craziest bac...</td>\n",
       "      <td>[(what, PRON), (movies, NOUN), (do, AUX), (you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is something you do that you know is bad ...</td>\n",
       "      <td>[(what, PRON), (is, AUX), (something, PRON), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for me it's smelling sharpies lol</td>\n",
       "      <td>[(for, ADP), (me, PRON), (it, PRON), ('s, AUX)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  What is your creepy/paranormal experience that...   \n",
       "1  What is something you have witnessed but no on...   \n",
       "2  what movies do you think have the craziest bac...   \n",
       "3  What is something you do that you know is bad ...   \n",
       "4                  for me it's smelling sharpies lol   \n",
       "\n",
       "                                            POS_Tags  \n",
       "0  [(what, PRON), (is, AUX), (your, PRON), (creep...  \n",
       "1  [(what, PRON), (is, AUX), (something, PRON), (...  \n",
       "2  [(what, PRON), (movies, NOUN), (do, AUX), (you...  \n",
       "3  [(what, PRON), (is, AUX), (something, PRON), (...  \n",
       "4  [(for, ADP), (me, PRON), (it, PRON), ('s, AUX)...  "
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply Spacy POS tagging on data and save in the column name \"POS_Tags\"\n",
    "df['POS_Tags'] = df['Text'].apply(pos_tag)\n",
    "\n",
    "# Explore data after SpaCy POS tagging\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for Training\n",
    "\n",
    "Next, we initialise a list of words with its corresponding POS tags for ease of training in the later steps (to\n",
    "calculate probabilities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what', 'PRON'),\n",
       " ('is', 'AUX'),\n",
       " ('your', 'PRON'),\n",
       " ('creepy', 'ADJ'),\n",
       " ('/', 'SYM'),\n",
       " ('paranormal', 'ADJ'),\n",
       " ('experience', 'NOUN'),\n",
       " ('that', 'PRON'),\n",
       " ('you', 'PRON'),\n",
       " ('ca', 'AUX'),\n",
       " ('n’t', 'PART'),\n",
       " ('explain', 'VERB'),\n",
       " ('?', 'PUNCT'),\n",
       " ('what', 'PRON'),\n",
       " ('is', 'AUX'),\n",
       " ('something', 'PRON'),\n",
       " ('you', 'PRON'),\n",
       " ('have', 'AUX'),\n",
       " ('witnessed', 'VERB'),\n",
       " ('but', 'CCONJ'),\n",
       " ('no', 'DET'),\n",
       " ('one', 'NOUN'),\n",
       " ('will', 'AUX'),\n",
       " ('believe', 'VERB'),\n",
       " ('?', 'PUNCT'),\n",
       " ('what', 'PRON'),\n",
       " ('movies', 'NOUN'),\n",
       " ('do', 'AUX'),\n",
       " ('you', 'PRON'),\n",
       " ('think', 'VERB'),\n",
       " ('have', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('craziest', 'ADJ'),\n",
       " ('backstories', 'NOUN'),\n",
       " ('?', 'PUNCT'),\n",
       " ('what', 'PRON'),\n",
       " ('is', 'AUX'),\n",
       " ('something', 'PRON'),\n",
       " ('you', 'PRON'),\n",
       " ('do', 'VERB'),\n",
       " ('that', 'PRON'),\n",
       " ('you', 'PRON'),\n",
       " ('know', 'VERB'),\n",
       " ('is', 'AUX'),\n",
       " ('bad', 'ADJ'),\n",
       " ('for', 'ADP'),\n",
       " ('you', 'PRON'),\n",
       " ('?', 'PUNCT'),\n",
       " ('for', 'ADP'),\n",
       " ('me', 'PRON'),\n",
       " ('it', 'PRON'),\n",
       " (\"'s\", 'AUX'),\n",
       " ('smelling', 'VERB'),\n",
       " ('sharpies', 'NOUN'),\n",
       " ('lol', 'NOUN'),\n",
       " ('indulge', 'PROPN'),\n",
       " ('in', 'ADP'),\n",
       " ('my', 'PRON'),\n",
       " ('baser', 'NOUN'),\n",
       " ('instincts', 'NOUN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('but', 'CCONJ'),\n",
       " ('i', 'PRON'),\n",
       " ('ca', 'AUX'),\n",
       " (\"n't\", 'PART'),\n",
       " ('resist', 'VERB'),\n",
       " ('.', 'PUNCT'),\n",
       " ('they', 'PRON'),\n",
       " (\"'re\", 'AUX'),\n",
       " ('like', 'ADP'),\n",
       " ('gravity', 'NOUN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('what', 'PRON'),\n",
       " ('are', 'AUX'),\n",
       " ('baser', 'ADJ'),\n",
       " ('instincts', 'NOUN'),\n",
       " ('?', 'PUNCT'),\n",
       " ('where', 'SCONJ'),\n",
       " ('does', 'AUX'),\n",
       " ('someone', 'PRON'),\n",
       " ('go', 'VERB'),\n",
       " ('to', 'PART'),\n",
       " ('ask', 'VERB'),\n",
       " ('for', 'ADP'),\n",
       " ('help', 'NOUN'),\n",
       " ('with', 'ADP'),\n",
       " ('creating', 'VERB'),\n",
       " ('and', 'CCONJ'),\n",
       " ('marketing', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('invention', 'NOUN'),\n",
       " ('without', 'ADP'),\n",
       " ('risk', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('theft', 'NOUN'),\n",
       " ('?', 'PUNCT'),\n",
       " ('for', 'ADP'),\n",
       " ('patenting', 'VERB'),\n",
       " ('it', 'PRON'),\n",
       " ('what', 'PRON'),\n",
       " ('is', 'AUX'),\n",
       " ('the', 'DET'),\n",
       " ('best', 'ADJ'),\n",
       " ('vacation', 'NOUN'),\n",
       " ('you', 'PRON'),\n",
       " ('’ve', 'AUX'),\n",
       " ('had', 'VERB'),\n",
       " ('?', 'PUNCT'),\n",
       " ('goodfellas', 'PROPN'),\n",
       " ('ou', 'ADP'),\n",
       " ('cassino', 'PROPN'),\n",
       " ('which', 'DET'),\n",
       " ('one', 'PRON'),\n",
       " ('is', 'AUX'),\n",
       " ('best', 'ADJ'),\n",
       " ('for', 'ADP'),\n",
       " ('you', 'PRON'),\n",
       " ('?', 'PUNCT'),\n",
       " ('what', 'PRON'),\n",
       " ('is', 'AUX'),\n",
       " ('cassino', 'ADJ'),\n",
       " ('?', 'PUNCT'),\n",
       " ('a', 'DET'),\n",
       " ('shoe', 'NOUN'),\n",
       " ('brand', 'NOUN'),\n",
       " ('i', 'PRON'),\n",
       " ('’m', 'VERB'),\n",
       " ('not', 'PART'),\n",
       " ('familiar', 'ADJ'),\n",
       " ('with', 'ADP'),\n",
       " ('?', 'PUNCT'),\n",
       " ('it', 'PRON'),\n",
       " ('’s', 'VERB'),\n",
       " ('goodfellas', 'PROPN'),\n",
       " (',', 'PUNCT'),\n",
       " ('but', 'CCONJ'),\n",
       " ('casino', 'PROPN'),\n",
       " ('is', 'AUX'),\n",
       " ('great', 'ADJ'),\n",
       " ('too', 'ADV'),\n",
       " ('what', 'PRON'),\n",
       " ('is', 'AUX'),\n",
       " ('your', 'PRON'),\n",
       " ('favorite', 'ADJ'),\n",
       " ('shoe', 'NOUN'),\n",
       " ('brand', 'NOUN'),\n",
       " ('?', 'PUNCT'),\n",
       " ('whatever', 'PRON'),\n",
       " ('is', 'AUX'),\n",
       " ('cheap', 'ADJ'),\n",
       " ('.', 'PUNCT'),\n",
       " ('currently', 'ADV'),\n",
       " ('have', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('nice', 'ADJ'),\n",
       " ('pair', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('sketchers', 'NOUN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('nice', 'ADJ'),\n",
       " ('try', 'VERB'),\n",
       " ('advertisers', 'NOUN'),\n",
       " ('vans', 'NOUN'),\n",
       " ('hablokens', 'NOUN'),\n",
       " ('shoenice', 'ADJ'),\n",
       " ('danner', 'PROPN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('a', 'DET'),\n",
       " ('little', 'ADJ'),\n",
       " ('pricy', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('but', 'CCONJ'),\n",
       " ('very', 'ADV'),\n",
       " ('durable', 'ADJ'),\n",
       " ('.', 'PUNCT'),\n",
       " ('swore', 'PROPN'),\n",
       " ('by', 'ADP'),\n",
       " ('skechers', 'PROPN'),\n",
       " ('for', 'ADP'),\n",
       " ('most', 'ADJ'),\n",
       " ('of', 'ADP'),\n",
       " ('my', 'PRON'),\n",
       " ('20s', 'NOUN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('they', 'PRON'),\n",
       " ('make', 'VERB'),\n",
       " ('some', 'DET'),\n",
       " ('solid', 'ADJ'),\n",
       " ('shoes', 'NOUN'),\n",
       " ('a', 'DET'),\n",
       " ('cloud', 'NOUN'),\n",
       " ('appears', 'VERB'),\n",
       " ('above', 'ADP'),\n",
       " ('your', 'PRON'),\n",
       " ('head', 'NOUN'),\n",
       " ('and', 'CCONJ'),\n",
       " ('a', 'DET'),\n",
       " ('beam', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('light', 'NOUN'),\n",
       " ('comes', 'AUX'),\n",
       " ('shining', 'VERB'),\n",
       " ('down', 'ADP'),\n",
       " ('on', 'ADP'),\n",
       " ('you', 'PRON'),\n",
       " ('!', 'PUNCT'),\n",
       " ('what', 'PRON'),\n",
       " (\"'s\", 'AUX'),\n",
       " ('your', 'PRON'),\n",
       " ('next', 'ADJ'),\n",
       " ('move', 'NOUN'),\n",
       " ('?', 'PUNCT'),\n",
       " ('quit', 'PROPN'),\n",
       " ('drugs', 'NOUN'),\n",
       " ('call', 'VERB'),\n",
       " ('nasa', 'PROPN'),\n",
       " ('that', 'SCONJ'),\n",
       " ('aliens', 'NOUN'),\n",
       " ('are', 'AUX'),\n",
       " ('found', 'VERB'),\n",
       " ('take', 'VERB'),\n",
       " ('another', 'DET'),\n",
       " ('hit', 'NOUN'),\n",
       " ('retreat', 'NOUN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('i', 'PRON'),\n",
       " ('hate', 'VERB'),\n",
       " ('light', 'ADJ'),\n",
       " ('.', 'PUNCT'),\n",
       " ('i', 'PRON'),\n",
       " ('’ve', 'AUX'),\n",
       " ('seen', 'VERB'),\n",
       " ('moonbeam', 'PROPN'),\n",
       " ('cast', 'VERB'),\n",
       " ('enough', 'ADV'),\n",
       " ('in', 'ADP'),\n",
       " ('baulders', 'PROPN'),\n",
       " ('gate', 'PROPN'),\n",
       " ('to', 'PART'),\n",
       " ('know', 'VERB'),\n",
       " ('to', 'PART'),\n",
       " ('dodge', 'VERB'),\n",
       " ('it', 'PRON'),\n",
       " ('.', 'PUNCT'),\n",
       " ('what', 'PRON'),\n",
       " ('do', 'AUX'),\n",
       " ('you', 'PRON'),\n",
       " ('think', 'VERB'),\n",
       " ('about', 'ADP'),\n",
       " ('when', 'SCONJ'),\n",
       " ('you', 'PRON'),\n",
       " ('’re', 'VERB'),\n",
       " ('too', 'ADV'),\n",
       " ('lazy', 'ADJ'),\n",
       " ('to', 'PART'),\n",
       " ('get', 'VERB'),\n",
       " ('up', 'ADP'),\n",
       " ('?', 'PUNCT'),\n",
       " ('i', 'PRON'),\n",
       " ('will', 'AUX'),\n",
       " ('feel', 'VERB'),\n",
       " ('worse', 'ADJ'),\n",
       " ('if', 'SCONJ'),\n",
       " ('i', 'PRON'),\n",
       " ('stay', 'VERB'),\n",
       " ('at', 'ADP'),\n",
       " ('home', 'NOUN'),\n",
       " ('all', 'DET'),\n",
       " ('day', 'NOUN'),\n",
       " ('read', 'VERB'),\n",
       " ('what', 'PRON'),\n",
       " ('is', 'AUX'),\n",
       " ('your', 'PRON'),\n",
       " ('favorite', 'ADJ'),\n",
       " ('album', 'NOUN'),\n",
       " ('?', 'PUNCT'),\n",
       " ('waka', 'PROPN'),\n",
       " ('waka', 'PROPN'),\n",
       " ('by', 'ADP'),\n",
       " ('shakira', 'PROPN'),\n",
       " ('norman', 'PROPN'),\n",
       " ('fcking', 'PROPN'),\n",
       " ('rockwell', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('lana', 'PROPN'),\n",
       " ('del', 'PROPN'),\n",
       " ('rey', 'PROPN'),\n",
       " ('faces', 'NOUN'),\n",
       " ('by', 'ADP'),\n",
       " ('mac', 'PROPN'),\n",
       " ('miller', 'PROPN'),\n",
       " ('i', 'PRON'),\n",
       " ('have', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('few', 'ADJ'),\n",
       " ('replies', 'NOUN'),\n",
       " ('aside', 'ADV'),\n",
       " (',', 'PUNCT'),\n",
       " ('that', 'PRON'),\n",
       " ('is', 'AUX'),\n",
       " ('a', 'DET'),\n",
       " ('really', 'ADV'),\n",
       " ('good', 'ADJ'),\n",
       " ('question', 'NOUN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('impera', 'NOUN'),\n",
       " ('by', 'ADP'),\n",
       " ('ghost', 'PROPN'),\n",
       " ('what', 'PRON'),\n",
       " ('places', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('reddit', 'PROPN'),\n",
       " ('can', 'AUX'),\n",
       " ('someone', 'PRON'),\n",
       " ('self', 'NOUN'),\n",
       " ('publish', 'VERB'),\n",
       " ('/', 'SYM'),\n",
       " ('promote', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('book', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('in', 'ADP'),\n",
       " ('progress', 'NOUN'),\n",
       " ('or', 'CCONJ'),\n",
       " ('complete', 'ADJ'),\n",
       " ('?', 'PUNCT'),\n",
       " ('.', 'PUNCT'),\n",
       " ('hopefully', 'ADV'),\n",
       " ('your', 'PRON'),\n",
       " ('book', 'NOUN'),\n",
       " ('ad', 'NOUN'),\n",
       " ('will', 'AUX'),\n",
       " ('be', 'AUX'),\n",
       " ('better', 'ADJ'),\n",
       " ('than', 'ADP'),\n",
       " ('whoever', 'PRON'),\n",
       " ('else', 'ADV'),\n",
       " ('is', 'AUX'),\n",
       " ('advertsing', 'VERB'),\n",
       " ('here', 'ADV'),\n",
       " ('.', 'PUNCT'),\n",
       " ('as', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('man', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('how', 'SCONJ'),\n",
       " ('do', 'AUX'),\n",
       " ('you', 'PRON'),\n",
       " ('communicate', 'VERB'),\n",
       " ('you', 'PRON'),\n",
       " ('would', 'AUX'),\n",
       " ('like', 'VERB'),\n",
       " ('more', 'ADJ'),\n",
       " ('affection', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('your', 'PRON'),\n",
       " ('partner', 'NOUN'),\n",
       " ('?', 'PUNCT'),\n",
       " ('with', 'ADP'),\n",
       " ('your', 'PRON'),\n",
       " ('mouth', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('and', 'CCONJ'),\n",
       " ('words', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('and', 'CCONJ'),\n",
       " ('also', 'ADV'),\n",
       " ('by', 'ADP'),\n",
       " ('listening', 'VERB'),\n",
       " ('to', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('reasons', 'NOUN'),\n",
       " ('why', 'SCONJ'),\n",
       " ('they', 'PRON'),\n",
       " ('may', 'AUX'),\n",
       " ('be', 'AUX'),\n",
       " ('resistant', 'ADJ'),\n",
       " ('to', 'ADP'),\n",
       " ('giving', 'VERB'),\n",
       " ('it', 'PRON'),\n",
       " ('to', 'ADP'),\n",
       " ('you', 'PRON'),\n",
       " ('i', 'PRON'),\n",
       " ('would', 'AUX'),\n",
       " ('like', 'VERB'),\n",
       " ('some', 'DET'),\n",
       " ('affection', 'NOUN'),\n",
       " ('i', 'PRON'),\n",
       " ('feel', 'VERB'),\n",
       " ('like', 'SCONJ'),\n",
       " ('we', 'PRON'),\n",
       " (\"'re\", 'AUX'),\n",
       " ('drifting', 'VERB'),\n",
       " ('apart', 'ADV'),\n",
       " ('romantically', 'ADV'),\n",
       " ('and', 'CCONJ'),\n",
       " ('i', 'PRON'),\n",
       " (\"'d\", 'AUX'),\n",
       " ('like', 'VERB'),\n",
       " ('us', 'PRON'),\n",
       " ('both', 'PRON'),\n",
       " ('to', 'PART'),\n",
       " ('put', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('more', 'ADJ'),\n",
       " ('effort', 'NOUN'),\n",
       " ('so', 'SCONJ'),\n",
       " ('we', 'PRON'),\n",
       " ('stay', 'VERB'),\n",
       " ('close', 'ADJ'),\n",
       " ('.', 'PUNCT'),\n",
       " ('music', 'NOUN'),\n",
       " ('lovers', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('what', 'DET'),\n",
       " ('song', 'NOUN'),\n",
       " ('would', 'AUX'),\n",
       " ('you', 'PRON'),\n",
       " ('recommend', 'VERB'),\n",
       " ('to', 'ADP'),\n",
       " ('someone', 'PRON'),\n",
       " ('needing', 'VERB'),\n",
       " ('to', 'PART'),\n",
       " ('chill', 'VERB'),\n",
       " ('out', 'ADP'),\n",
       " ('?', 'PUNCT'),\n",
       " ('no', 'INTJ'),\n",
       " ('ordinary', 'ADJ'),\n",
       " ('love', 'PROPN'),\n",
       " ('-', 'PUNCT'),\n",
       " ('sade', 'PROPN'),\n",
       " ('what', 'PRON'),\n",
       " ('are', 'AUX'),\n",
       " ('your', 'PRON'),\n",
       " ('thoughts', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('limerence', 'NOUN'),\n",
       " ('and', 'CCONJ'),\n",
       " ('how', 'SCONJ'),\n",
       " ('do', 'AUX'),\n",
       " ('you', 'PRON'),\n",
       " ('overcome', 'VERB'),\n",
       " ('it', 'PRON'),\n",
       " ('?', 'PUNCT'),\n",
       " ('life', 'NOUN'),\n",
       " ('is', 'AUX'),\n",
       " ('very', 'ADV'),\n",
       " ('difficult', 'ADJ'),\n",
       " ('.', 'PUNCT'),\n",
       " ('therapy', 'NOUN'),\n",
       " ('is', 'AUX'),\n",
       " ('probably', 'ADV'),\n",
       " ('a', 'DET'),\n",
       " ('good', 'ADJ'),\n",
       " ('idea', 'NOUN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('what', 'PRON'),\n",
       " ('gen', 'PROPN'),\n",
       " ('z', 'PROPN'),\n",
       " ('slang', 'PROPN'),\n",
       " ('do', 'AUX'),\n",
       " ('you', 'PRON'),\n",
       " ('think', 'VERB'),\n",
       " ('will', 'AUX'),\n",
       " ('continue', 'VERB'),\n",
       " ('to', 'PART'),\n",
       " ('be', 'AUX'),\n",
       " ('used', 'VERB'),\n",
       " ('into', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('future', 'NOUN'),\n",
       " ('?', 'PUNCT'),\n",
       " ('bet', 'VERB'),\n",
       " ('“', 'PUNCT'),\n",
       " ('bro', 'NOUN'),\n",
       " ('”', 'PUNCT'),\n",
       " ('gen', 'PROPN'),\n",
       " ('z', 'PROPN'),\n",
       " ('seems', 'VERB'),\n",
       " ('to', 'PART'),\n",
       " ('have', 'AUX'),\n",
       " ('taken', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('relatively', 'ADV'),\n",
       " ('harmless', 'ADJ'),\n",
       " ('word', 'NOUN'),\n",
       " ('and', 'CCONJ'),\n",
       " ('turned', 'VERB'),\n",
       " ('it', 'PRON'),\n",
       " ('into', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('fucking', 'ADJ'),\n",
       " ('king', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('cringe', 'NOUN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('i', 'PRON'),\n",
       " ('’m', 'VERB'),\n",
       " ('so', 'ADV'),\n",
       " ('sick', 'ADJ'),\n",
       " ('of', 'ADP'),\n",
       " ('being', 'AUX'),\n",
       " ('called', 'VERB'),\n",
       " ('bro', 'NOUN'),\n",
       " ('it', 'PRON'),\n",
       " ('’s', 'VERB'),\n",
       " ('not', 'PART'),\n",
       " ('even', 'ADV'),\n",
       " ('funny', 'ADJ'),\n",
       " ('.', 'PUNCT'),\n",
       " ('now', 'ADV'),\n",
       " ('here', 'ADV'),\n",
       " ('come', 'VERB'),\n",
       " ('all', 'DET'),\n",
       " ('the', 'DET'),\n",
       " ('generic', 'ADJ'),\n",
       " ('nerds', 'NOUN'),\n",
       " ('that', 'PRON'),\n",
       " ('are', 'AUX'),\n",
       " ('about', 'ADJ'),\n",
       " ('to', 'PART'),\n",
       " ('reply', 'VERB'),\n",
       " ('and', 'CCONJ'),\n",
       " ('call', 'VERB'),\n",
       " ('me', 'PRON'),\n",
       " ('bro', 'ADV'),\n",
       " ('.', 'PUNCT'),\n",
       " ('fair', 'ADJ'),\n",
       " ('i', 'PRON'),\n",
       " (\"'ll\", 'AUX'),\n",
       " ('die', 'VERB'),\n",
       " ('on', 'ADP'),\n",
       " ('this', 'DET'),\n",
       " ('hill', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('but', 'CCONJ'),\n",
       " ('reply', 'VERB'),\n",
       " ('more', 'ADJ'),\n",
       " ('than', 'ADP'),\n",
       " ('twice', 'DET'),\n",
       " ('a', 'DET'),\n",
       " ('day', 'NOUN'),\n",
       " ('with', 'ADP'),\n",
       " ('this', 'PRON'),\n",
       " ('...', 'PUNCT'),\n",
       " ('and', 'CCONJ'),\n",
       " ('culling', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('wheat', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('chaff', 'NOUN'),\n",
       " ('is', 'AUX'),\n",
       " (\"'\", 'PUNCT'),\n",
       " ('fair', 'ADJ'),\n",
       " (\"'\", 'PUNCT'),\n",
       " ('goat', 'PROPN'),\n",
       " ('caught', 'VERB'),\n",
       " ('on', 'ADP'),\n",
       " ('quick', 'ADJ'),\n",
       " ('.', 'PUNCT'),\n",
       " ('i', 'PRON'),\n",
       " ('’ll', 'AUX'),\n",
       " ('start', 'VERB'),\n",
       " ('.', 'PUNCT'),\n",
       " ('i', 'PRON'),\n",
       " ('think', 'VERB'),\n",
       " ('‘', 'PUNCT'),\n",
       " ('fr', 'PROPN'),\n",
       " ('’', 'PUNCT'),\n",
       " ('has', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('chance', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('as', 'SCONJ'),\n",
       " ('it', 'PRON'),\n",
       " ('is', 'AUX'),\n",
       " ('clear', 'ADJ'),\n",
       " (',', 'PUNCT'),\n",
       " ('simple', 'ADJ'),\n",
       " (',', 'PUNCT'),\n",
       " ('and', 'CCONJ'),\n",
       " ('not', 'PART'),\n",
       " ('overly', 'ADV'),\n",
       " ('obnoxious', 'ADJ'),\n",
       " ('when', 'SCONJ'),\n",
       " ('used', 'VERB'),\n",
       " ('correctly', 'ADV'),\n",
       " ('.', 'PUNCT'),\n",
       " ('rizzler', 'PROPN'),\n",
       " ('gyatt', 'NOUN'),\n",
       " ('bruh', 'NOUN'),\n",
       " ('skull', 'PROPN'),\n",
       " ('emoji', 'PROPN'),\n",
       " ('dude', 'NOUN'),\n",
       " ('will', 'AUX'),\n",
       " ('always', 'ADV'),\n",
       " ('be', 'AUX'),\n",
       " ('superior', 'ADJ'),\n",
       " ('.', 'PUNCT'),\n",
       " ('bud', 'PROPN'),\n",
       " (',', 'PUNCT'),\n",
       " ('you', 'PRON'),\n",
       " ('did', 'VERB'),\n",
       " ('that', 'PRON'),\n",
       " ('right', 'ADJ'),\n",
       " ('fr', 'VERB'),\n",
       " ('that', 'PRON'),\n",
       " (\"'s\", 'AUX'),\n",
       " ('not', 'PART'),\n",
       " ('gen', 'PROPN'),\n",
       " ('z.', 'PROPN'),\n",
       " ('people', 'PROPN'),\n",
       " ('have', 'AUX'),\n",
       " ('said', 'VERB'),\n",
       " ('that', 'SCONJ'),\n",
       " ('before', 'SCONJ'),\n",
       " ('gen', 'PROPN'),\n",
       " ('z', 'PROPN'),\n",
       " ('even', 'ADV'),\n",
       " ('existed', 'VERB'),\n",
       " ('.', 'PUNCT'),\n",
       " ('it', 'PRON'),\n",
       " (\"'s\", 'AUX'),\n",
       " ('african', 'ADJ'),\n",
       " ('american', 'ADJ'),\n",
       " ('vernacular', 'NOUN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('yesssssss', 'NOUN'),\n",
       " ('...', 'PUNCT'),\n",
       " ('what', 'PRON'),\n",
       " ('does', 'AUX'),\n",
       " ('it', 'PRON'),\n",
       " ('mean', 'VERB'),\n",
       " ('?', 'PUNCT'),\n",
       " ('what', 'PRON'),\n",
       " ('if', 'SCONJ'),\n",
       " ('the', 'DET'),\n",
       " ('sun', 'NOUN'),\n",
       " ('was', 'AUX'),\n",
       " ('a', 'DET'),\n",
       " ('big', 'ADJ'),\n",
       " ('antenna', 'NOUN'),\n",
       " ('what', 'PRON'),\n",
       " ('would', 'AUX'),\n",
       " ('you', 'PRON'),\n",
       " ('make', 'VERB'),\n",
       " ('out', 'ADP'),\n",
       " ('of', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('?', 'PUNCT'),\n",
       " ('tv', 'NOUN'),\n",
       " ('with', 'ADP'),\n",
       " ('color', 'NOUN'),\n",
       " ('?', 'PUNCT'),\n",
       " ('yes', 'INTJ'),\n",
       " ('what', 'PRON'),\n",
       " ('is', 'AUX'),\n",
       " ('the', 'DET'),\n",
       " ('most', 'ADV'),\n",
       " ('asked', 'PROPN'),\n",
       " ('question', 'PROPN'),\n",
       " ('on', 'ADP'),\n",
       " ('this', 'DET'),\n",
       " ('subreddit', 'NOUN'),\n",
       " ('?', 'PUNCT'),\n",
       " ('if', 'SCONJ'),\n",
       " ('you', 'PRON'),\n",
       " ('won', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('lottery', 'PROPN'),\n",
       " (',', 'PUNCT'),\n",
       " ('what', 'PRON'),\n",
       " ('would', 'AUX'),\n",
       " ('you', 'PRON'),\n",
       " ('buy', 'VERB'),\n",
       " ('first', 'ADV'),\n",
       " ('?', 'PUNCT'),\n",
       " ('top', 'ADJ'),\n",
       " ('comment', 'NOUN'),\n",
       " (':', 'PUNCT'),\n",
       " ('that', 'DET'),\n",
       " ('one', 'NUM'),\n",
       " ('thing', 'NOUN'),\n",
       " ('that', 'PRON'),\n",
       " ('lawyer', 'NOUN'),\n",
       " ('posted', 'VERB'),\n",
       " ('.', 'PUNCT'),\n",
       " ('redditors', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('have', 'AUX'),\n",
       " ('you', 'PRON'),\n",
       " ('ever', 'ADV'),\n",
       " (\"sex'd\", 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('sex', 'NOUN'),\n",
       " ('?', 'PUNCT'),\n",
       " ('if', 'SCONJ'),\n",
       " ('not', 'PART'),\n",
       " (',', 'PUNCT'),\n",
       " ('why', 'SCONJ'),\n",
       " ('?', 'PUNCT'),\n",
       " ('do', 'AUX'),\n",
       " ('you', 'PRON'),\n",
       " ('sex', 'VERB'),\n",
       " ('and', 'CCONJ'),\n",
       " ('if', 'SCONJ'),\n",
       " ('so', 'ADV'),\n",
       " (',', 'PUNCT'),\n",
       " ('say', 'VERB'),\n",
       " ('all', 'DET'),\n",
       " ('the', 'DET'),\n",
       " ('things', 'NOUN'),\n",
       " ('about', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('anything', 'PRON'),\n",
       " ('with', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('word', 'NOUN'),\n",
       " ('sex', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('.', 'PUNCT'),\n",
       " ('if', 'SCONJ'),\n",
       " ('you', 'PRON'),\n",
       " ('could', 'AUX'),\n",
       " ('ask', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('historical', 'ADJ'),\n",
       " ('figure', 'NOUN'),\n",
       " ('one', 'NUM'),\n",
       " ('question', 'NOUN'),\n",
       " ('etc', 'X'),\n",
       " ('etc', 'X'),\n",
       " ('pretty', 'ADV'),\n",
       " ('much', 'ADV'),\n",
       " ('anything', 'PRON'),\n",
       " ('you', 'PRON'),\n",
       " (\"'d\", 'AUX'),\n",
       " ('imagine', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('horny', 'NOUN'),\n",
       " ('13', 'NUM'),\n",
       " ('year', 'NOUN'),\n",
       " ('old', 'ADJ'),\n",
       " ('with', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('social', 'ADJ'),\n",
       " ('skills', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('tea', 'NOUN'),\n",
       " ('leaf', 'NOUN'),\n",
       " ('would', 'AUX'),\n",
       " ('ask', 'VERB'),\n",
       " ('about', 'ADP'),\n",
       " ('sex', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('but', 'CCONJ'),\n",
       " ('with', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('grammar', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('3', 'NUM'),\n",
       " ('year', 'NOUN'),\n",
       " ('old', 'ADJ'),\n",
       " ('.', 'PUNCT'),\n",
       " ('if', 'SCONJ'),\n",
       " ('you', 'PRON'),\n",
       " ('win', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('lottery', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('what', 'PRON'),\n",
       " ('would', 'AUX'),\n",
       " ('you', 'PRON'),\n",
       " ('do', 'VERB'),\n",
       " ('…', 'PUNCT'),\n",
       " ('if', 'SCONJ'),\n",
       " ('you', 'PRON'),\n",
       " ('could', 'AUX'),\n",
       " ('talk', 'VERB'),\n",
       " ('to', 'ADP'),\n",
       " ('your', 'PRON'),\n",
       " ('younger', 'ADJ'),\n",
       " ('self', 'NOUN'),\n",
       " ('what', 'PRON'),\n",
       " ('would', 'AUX'),\n",
       " ('you', 'PRON'),\n",
       " ('say', 'VERB'),\n",
       " ('…', 'PUNCT'),\n",
       " ('those', 'DET'),\n",
       " ('two', 'NUM'),\n",
       " ('questions', 'NOUN'),\n",
       " ('pop', 'VERB'),\n",
       " ('up', 'ADP'),\n",
       " ('like', 'ADP'),\n",
       " ('28', 'NUM'),\n",
       " ('times', 'NOUN'),\n",
       " ('a', 'DET'),\n",
       " ('day', 'NOUN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('what', 'PRON'),\n",
       " ('is', 'AUX'),\n",
       " ('something', 'PRON'),\n",
       " ('you', 'PRON'),\n",
       " ('love', 'VERB'),\n",
       " ('but', 'CCONJ'),\n",
       " ('everybody', 'PRON'),\n",
       " ('hates', 'VERB'),\n",
       " ('?', 'PUNCT'),\n",
       " ('god', 'PROPN'),\n",
       " ('smal', 'ADJ'),\n",
       " ('titties', 'NOUN'),\n",
       " ('eating', 'VERB'),\n",
       " ('food', 'NOUN'),\n",
       " ('without', 'ADP'),\n",
       " ('condiments', 'NOUN'),\n",
       " ('i', 'PRON'),\n",
       " ('prefer', 'VERB'),\n",
       " ('whiterun', 'PROPN'),\n",
       " ('personally', 'ADV'),\n",
       " ('pineapple', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('pizza', 'PROPN'),\n",
       " ('🍕', 'PROPN'),\n",
       " ('🍍', 'PROPN'),\n",
       " ('🤤', 'VERB'),\n",
       " ('underground', 'ADJ'),\n",
       " ('trains', 'NOUN'),\n",
       " ('like', 'ADP'),\n",
       " ('new', 'PROPN'),\n",
       " ('york', 'PROPN'),\n",
       " ('or', 'CCONJ'),\n",
       " ('london', 'PROPN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('i', 'PRON'),\n",
       " ('love', 'VERB'),\n",
       " ('them', 'PRON'),\n",
       " ('no', 'ADV'),\n",
       " ('matter', 'ADV'),\n",
       " ('how', 'SCONJ'),\n",
       " ('dirty', 'ADJ'),\n",
       " ('they', 'PRON'),\n",
       " ('are', 'AUX'),\n",
       " ('amen', 'INTJ'),\n",
       " ('.', 'PUNCT'),\n",
       " ('you', 'PRON'),\n",
       " ('need', 'VERB'),\n",
       " ('to', 'PART'),\n",
       " ('write', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('unpopular', 'ADJ'),\n",
       " ('opinion', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('this', 'PRON'),\n",
       " ('.', 'PUNCT'),\n",
       " ('it', 'PRON'),\n",
       " ('is', 'AUX'),\n",
       " ('tasty', 'ADJ'),\n",
       " ('what', 'PRON'),\n",
       " ('’s', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('lie', 'NOUN'),\n",
       " ('your', 'PRON'),\n",
       " ('parents', 'NOUN'),\n",
       " ('told', 'VERB'),\n",
       " ('you', 'PRON'),\n",
       " ('?', 'PUNCT'),\n",
       " ('and', 'CCONJ'),\n",
       " ('how', 'SCONJ'),\n",
       " ('long', 'ADV'),\n",
       " ('did', 'AUX'),\n",
       " ('you', 'PRON'),\n",
       " ('believe', 'VERB'),\n",
       " ('it', 'PRON'),\n",
       " ('for', 'ADP'),\n",
       " ('?', 'PUNCT'),\n",
       " ('babies', 'NOUN'),\n",
       " ('were', 'AUX'),\n",
       " ('dropped', 'VERB'),\n",
       " ('off', 'ADP'),\n",
       " ('by', 'ADP'),\n",
       " ('angels', 'NOUN'),\n",
       " ('till', 'SCONJ'),\n",
       " ('i', 'PRON'),\n",
       " ('was', 'AUX'),\n",
       " ('12', 'NUM'),\n",
       " ('-illegal', 'ADJ'),\n",
       " ('to', 'PART'),\n",
       " ('turn', 'VERB'),\n",
       " ('on', 'ADP'),\n",
       " ('interior', 'ADJ'),\n",
       " ('lights', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('car', 'NOUN'),\n",
       " ('while', 'SCONJ'),\n",
       " ('driving', 'VERB'),\n",
       " ('-grandma', 'NOUN'),\n",
       " ('told', 'VERB'),\n",
       " ('us', 'PRON'),\n",
       " ('that', 'SCONJ'),\n",
       " ('the', 'DET'),\n",
       " ('canker', 'NOUN'),\n",
       " ('sores', 'VERB'),\n",
       " ('you', 'PRON'),\n",
       " ('get', 'VERB'),\n",
       " ('on', 'ADP'),\n",
       " ('your', 'PRON'),\n",
       " ('tongue', 'NOUN'),\n",
       " ('were', 'AUX'),\n",
       " ('“', 'PUNCT'),\n",
       " ('lie', 'NOUN'),\n",
       " ('bumps', 'NOUN'),\n",
       " ('”', 'PUNCT'),\n",
       " ('and', 'CCONJ'),\n",
       " ('only', 'ADV'),\n",
       " ('went', 'VERB'),\n",
       " ('away', 'ADV'),\n",
       " ('after', 'SCONJ'),\n",
       " ('you', 'PRON'),\n",
       " ('confessed', 'VERB'),\n",
       " ('.', 'PUNCT'),\n",
       " ('i', 'PRON'),\n",
       " ('believed', 'VERB'),\n",
       " ('these', 'PRON'),\n",
       " ('both', 'PRON'),\n",
       " ('till', 'SCONJ'),\n",
       " ('teenage', 'ADJ'),\n",
       " ('years', 'NOUN'),\n",
       " ('🥴', 'NOUN'),\n",
       " ('😂', 'ADP'),\n",
       " ('which', 'DET'),\n",
       " ('hobbyist', 'NOUN'),\n",
       " ('or', 'CCONJ'),\n",
       " ('aficionados', 'NOUN'),\n",
       " ('are', 'AUX'),\n",
       " ('the', 'DET'),\n",
       " ('biggest', 'ADJ'),\n",
       " ('douchebags', 'NOUN'),\n",
       " ('?', 'PUNCT'),\n",
       " ('what', 'PRON'),\n",
       " ('is', 'AUX'),\n",
       " ('it', 'PRON'),\n",
       " ('that', 'PRON'),\n",
       " ('?', 'PUNCT'),\n",
       " ('food', 'NOUN'),\n",
       " ('and', 'CCONJ'),\n",
       " ('drink', 'NOUN'),\n",
       " ('aficionados', 'NOUN'),\n",
       " ('are', 'AUX'),\n",
       " ('massive', 'ADJ'),\n",
       " ('douchebags', 'NOUN'),\n",
       " ('because', 'SCONJ'),\n",
       " ('they', 'PRON'),\n",
       " ('have', 'AUX'),\n",
       " ('introduced', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('hierarchy', 'NOUN'),\n",
       " ('into', 'ADP'),\n",
       " ('an', 'DET'),\n",
       " ('entirely', 'ADV'),\n",
       " ('subjective', 'ADJ'),\n",
       " ('area', 'NOUN'),\n",
       " ('.', 'PUNCT'),\n",
       " ('if', 'SCONJ'),\n",
       " ('someone', 'PRON'),\n",
       " ('does', 'AUX'),\n",
       " (\"n't\", 'PART'),\n",
       " ('like', 'VERB'),\n",
       " ('seasoned', 'VERB'),\n",
       " ('food', 'NOUN'),\n",
       " ('they', 'PRON'),\n",
       " ('are', 'AUX'),\n",
       " (\"n't\", 'PART'),\n",
       " ('inferior', 'ADJ'),\n",
       " ('.', 'PUNCT'),\n",
       " ('if', 'SCONJ'),\n",
       " ('someone', 'PRON'),\n",
       " ('does', 'AUX'),\n",
       " (\"n't\", 'PART'),\n",
       " ('like', 'VERB'),\n",
       " ('spice', 'NOUN'),\n",
       " ('they', 'PRON'),\n",
       " ('are', 'AUX'),\n",
       " (\"n't\", 'PART'),\n",
       " ('weaker', 'ADJ'),\n",
       " ('.', 'PUNCT'),\n",
       " ('if', 'SCONJ'),\n",
       " ('someone', 'PRON'),\n",
       " ('does', 'AUX'),\n",
       " (\"n't\", 'PART'),\n",
       " ('like', 'VERB'),\n",
       " ('x', 'NOUN'),\n",
       " ('cuisine', 'NOUN'),\n",
       " ('they', 'PRON'),\n",
       " ('are', 'AUX'),\n",
       " (\"n't\", 'PART'),\n",
       " ('culturally', 'ADV'),\n",
       " ...]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flattens POS_Tags of train_df into a single list of tuples\n",
    "flattened_list = [tup for sublist in df['POS_Tags'] for tup in sublist]\n",
    "flattened_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we also update our dataframe to have 2 new columns, `Words` and `Tags` which contains the words and\n",
    "tags separately for ease of training in the later steps (calculating the probabilities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>POS_Tags</th>\n",
       "      <th>Words</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Tag_Init</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is your creepy/paranormal experience that...</td>\n",
       "      <td>[(what, PRON), (is, AUX), (your, PRON), (creep...</td>\n",
       "      <td>[what, is, your, creepy, /, paranormal, experi...</td>\n",
       "      <td>[PRON, AUX, PRON, ADJ, SYM, ADJ, NOUN, PRON, P...</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is something you have witnessed but no on...</td>\n",
       "      <td>[(what, PRON), (is, AUX), (something, PRON), (...</td>\n",
       "      <td>[what, is, something, you, have, witnessed, bu...</td>\n",
       "      <td>[PRON, AUX, PRON, PRON, AUX, VERB, CCONJ, DET,...</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what movies do you think have the craziest bac...</td>\n",
       "      <td>[(what, PRON), (movies, NOUN), (do, AUX), (you...</td>\n",
       "      <td>[what, movies, do, you, think, have, the, craz...</td>\n",
       "      <td>[PRON, NOUN, AUX, PRON, VERB, VERB, DET, ADJ, ...</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is something you do that you know is bad ...</td>\n",
       "      <td>[(what, PRON), (is, AUX), (something, PRON), (...</td>\n",
       "      <td>[what, is, something, you, do, that, you, know...</td>\n",
       "      <td>[PRON, AUX, PRON, PRON, VERB, PRON, PRON, VERB...</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for me it's smelling sharpies lol</td>\n",
       "      <td>[(for, ADP), (me, PRON), (it, PRON), ('s, AUX)...</td>\n",
       "      <td>[for, me, it, 's, smelling, sharpies, lol]</td>\n",
       "      <td>[ADP, PRON, PRON, AUX, VERB, NOUN, NOUN]</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  What is your creepy/paranormal experience that...   \n",
       "1  What is something you have witnessed but no on...   \n",
       "2  what movies do you think have the craziest bac...   \n",
       "3  What is something you do that you know is bad ...   \n",
       "4                  for me it's smelling sharpies lol   \n",
       "\n",
       "                                            POS_Tags  \\\n",
       "0  [(what, PRON), (is, AUX), (your, PRON), (creep...   \n",
       "1  [(what, PRON), (is, AUX), (something, PRON), (...   \n",
       "2  [(what, PRON), (movies, NOUN), (do, AUX), (you...   \n",
       "3  [(what, PRON), (is, AUX), (something, PRON), (...   \n",
       "4  [(for, ADP), (me, PRON), (it, PRON), ('s, AUX)...   \n",
       "\n",
       "                                               Words  \\\n",
       "0  [what, is, your, creepy, /, paranormal, experi...   \n",
       "1  [what, is, something, you, have, witnessed, bu...   \n",
       "2  [what, movies, do, you, think, have, the, craz...   \n",
       "3  [what, is, something, you, do, that, you, know...   \n",
       "4         [for, me, it, 's, smelling, sharpies, lol]   \n",
       "\n",
       "                                                Tags Tag_Init  \n",
       "0  [PRON, AUX, PRON, ADJ, SYM, ADJ, NOUN, PRON, P...     PRON  \n",
       "1  [PRON, AUX, PRON, PRON, AUX, VERB, CCONJ, DET,...     PRON  \n",
       "2  [PRON, NOUN, AUX, PRON, VERB, VERB, DET, ADJ, ...     PRON  \n",
       "3  [PRON, AUX, PRON, PRON, VERB, PRON, PRON, VERB...     PRON  \n",
       "4           [ADP, PRON, PRON, AUX, VERB, NOUN, NOUN]      ADP  "
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract words and tags from the tuples in the 'POS_Tags' column\n",
    "df['Words'] = df['POS_Tags'].apply(lambda x: [pair[0] for pair in x])\n",
    "df['Tags'] = df['POS_Tags'].apply(lambda x: [pair[1] for pair in x])\n",
    "df['Tag_Init'] = df['Tags'].apply(lambda x: x[0])\n",
    "\n",
    "# Explore the updated dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we also prepare 2 sets, one containing all unique words in the corpus, and another all the unique tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of all unique words and tags\n",
    "all_words = set(word for word_list in df['Words'] for word in word_list)\n",
    "all_tags = set(tag for tag_list in df['Tags'] for tag in tag_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Learning\n",
    "\n",
    "In this section, we attempt to calculate the start, transition and emission probabilities based on the prepared data\n",
    "from the previous section. These probabilities will then be put together into matrices, called the initial state probability matrix, $\\pi$, transition probability matrix, $A$, and emission probability matrix, $B$, respectively.\n",
    "\n",
    "These matrices which contain the probabilities are necessary for us to perform POS tagging on a new sentence\n",
    "via Viterbi algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial State Probability\n",
    "\n",
    "The initial state probability is the probability of a sequence starting in state $s_i$.\n",
    "\n",
    "More precisely, $P(q_1 = s_i)=\\frac{Count(<S>s_i)}{Count(<S>)}$, where $<S>s_i = $ # of sentences starting with state $s_i$, $<S> = $ # of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of unique tags and words\n",
    "t_len = len(all_tags)\n",
    "w_len = len(all_words)\n",
    "\n",
    "# Get a list of unique tags\n",
    "unique_tag_list = list(all_tags)\n",
    "\n",
    "# Get a list of unique words\n",
    "unique_word_list = list(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialise an empty initial state probability matrix $\\pi$ of size 1 x `len(all_tags)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUM</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>PART</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>VERB</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SYM</th>\n",
       "      <th>AUX</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>X</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PRON</th>\n",
       "      <th>ADV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016487</td>\n",
       "      <td>0.081033</td>\n",
       "      <td>0.038494</td>\n",
       "      <td>0.020764</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.006299</td>\n",
       "      <td>0.008554</td>\n",
       "      <td>0.053348</td>\n",
       "      <td>0.112995</td>\n",
       "      <td>0.108951</td>\n",
       "      <td>0.006921</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.028229</td>\n",
       "      <td>0.055525</td>\n",
       "      <td>0.005288</td>\n",
       "      <td>0.115094</td>\n",
       "      <td>0.291625</td>\n",
       "      <td>0.049537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        NUM       DET      INTJ       ADP     SPACE     CCONJ      PART  \\\n",
       "0  0.016487  0.081033  0.038494  0.020764  0.000156  0.006299  0.008554   \n",
       "\n",
       "      SCONJ      VERB      NOUN     PUNCT     SYM       AUX       ADJ  \\\n",
       "0  0.053348  0.112995  0.108951  0.006921  0.0007  0.028229  0.055525   \n",
       "\n",
       "          X     PROPN      PRON       ADV  \n",
       "0  0.005288  0.115094  0.291625  0.049537  "
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an initial state probability matrix of dimension 1 x len(all_tags)\n",
    "pi = np.zeros((1, t_len))\n",
    "\n",
    "for i, tag in enumerate(unique_tag_list):\n",
    "    pi[0, i] = np.sum(df[\"Tag_Init\"] == tag)\n",
    "\n",
    "pi /= len(df)\n",
    "\n",
    "# Convert pi to a dataframe for better readability\n",
    "pi_df = pd.DataFrame(pi, columns = unique_tag_list)\n",
    "pi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emission Probability\n",
    "\n",
    "The emission probability is the probability of POS tag $s_i$ generating a particular word $w_k$ at any time $t$.\n",
    "\n",
    "More precisely, $P(o_t=w_k | q_t=s_i)=\\frac{Count(w_k, s_i)}{Count(s_i)}$, where $o_t=$ observed state at time $t$,\n",
    "$w_k=$ word $k$, $q_t=$ hidden state at time $t$, $s_i=$ POS tag $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we initialise an empty emission probability matrix $B$ of size `len(all_tags)` x `len(all_words)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disrespect</th>\n",
       "      <th>tfmr</th>\n",
       "      <th>dried</th>\n",
       "      <th>hath</th>\n",
       "      <th>9</th>\n",
       "      <th>grounded</th>\n",
       "      <th>mattress</th>\n",
       "      <th>immigrant</th>\n",
       "      <th>removing</th>\n",
       "      <th>gouger</th>\n",
       "      <th>...</th>\n",
       "      <th>unlike</th>\n",
       "      <th>whispered</th>\n",
       "      <th>foreseeable</th>\n",
       "      <th>combustion</th>\n",
       "      <th>teens</th>\n",
       "      <th>flex</th>\n",
       "      <th>level</th>\n",
       "      <th>caulken</th>\n",
       "      <th>time)and</th>\n",
       "      <th>cusack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTJ</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPACE</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCONJ</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PART</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCONJ</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNCT</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUX</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROPN</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 17917 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       disrespect     tfmr     dried      hath         9  grounded  mattress  \\\n",
       "NUM      0.000000  0.00000  0.000000  0.000000  0.006356  0.000000  0.000000   \n",
       "DET      0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "INTJ     0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "ADP      0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "SPACE    0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "CCONJ    0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "PART     0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "SCONJ    0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "VERB     0.000025  0.00000  0.000127  0.000025  0.000000  0.000000  0.000000   \n",
       "NOUN     0.000021  0.00000  0.000000  0.000000  0.000000  0.000000  0.000041   \n",
       "PUNCT    0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "SYM      0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "AUX      0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "ADJ      0.000000  0.00000  0.000000  0.000000  0.000000  0.000053  0.000000   \n",
       "X        0.000000  0.00000  0.000000  0.000000  0.004357  0.000000  0.000000   \n",
       "PROPN    0.000000  0.00011  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "PRON     0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "ADV      0.000000  0.00000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       immigrant  removing    gouger  ...    unlike  whispered  foreseeable  \\\n",
       "NUM     0.000000  0.000000  0.000000  ...  0.000000   0.000000     0.000000   \n",
       "DET     0.000000  0.000000  0.000000  ...  0.000000   0.000000     0.000000   \n",
       "INTJ    0.000000  0.000000  0.000000  ...  0.000000   0.000000     0.000000   \n",
       "ADP     0.000000  0.000000  0.000000  ...  0.000118   0.000000     0.000000   \n",
       "SPACE   0.000000  0.000000  0.000000  ...  0.000000   0.000000     0.000000   \n",
       "CCONJ   0.000000  0.000000  0.000000  ...  0.000000   0.000000     0.000000   \n",
       "PART    0.000000  0.000000  0.000000  ...  0.000000   0.000000     0.000000   \n",
       "SCONJ   0.000000  0.000000  0.000000  ...  0.000137   0.000000     0.000000   \n",
       "VERB    0.000000  0.000076  0.000000  ...  0.000000   0.000025     0.000000   \n",
       "NOUN    0.000062  0.000000  0.000021  ...  0.000000   0.000000     0.000000   \n",
       "PUNCT   0.000000  0.000000  0.000000  ...  0.000000   0.000000     0.000000   \n",
       "SYM     0.000000  0.000000  0.000000  ...  0.000000   0.000000     0.000000   \n",
       "AUX     0.000000  0.000000  0.000000  ...  0.000000   0.000000     0.000000   \n",
       "ADJ     0.000053  0.000000  0.000000  ...  0.000000   0.000000     0.000053   \n",
       "X       0.000000  0.000000  0.000000  ...  0.000000   0.000000     0.000000   \n",
       "PROPN   0.000000  0.000000  0.000000  ...  0.000000   0.000000     0.000000   \n",
       "PRON    0.000000  0.000000  0.000000  ...  0.000000   0.000000     0.000000   \n",
       "ADV     0.000000  0.000000  0.000000  ...  0.000000   0.000000     0.000000   \n",
       "\n",
       "       combustion     teens      flex     level   caulken  time)and    cusack  \n",
       "NUM      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "DET      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "INTJ     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "ADP      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "SPACE    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "CCONJ    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "PART     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "SCONJ    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "VERB     0.000000  0.000000  0.000000  0.000051  0.000025  0.000000  0.000000  \n",
       "NOUN     0.000062  0.000103  0.000021  0.000965  0.000000  0.000021  0.000000  \n",
       "PUNCT    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "SYM      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "AUX      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "ADJ      0.000000  0.000000  0.000107  0.000000  0.000000  0.000000  0.000000  \n",
       "X        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "PROPN    0.000000  0.000000  0.000110  0.000000  0.000000  0.000000  0.000219  \n",
       "PRON     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "ADV      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[18 rows x 17917 columns]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an emission probability matrix of dimension len(all_tags) x len(all_words)\n",
    "# Compute P(w_k | s_i) and storing in a T x V matrix\n",
    "B = np.zeros((t_len, w_len))\n",
    "\n",
    "# def calculate_emission_prob(word, tag, train_data):\n",
    "#     tag_list = [(t_word, t_tag) for t_word, t_tag in train_data if t_tag == tag]\n",
    "#     count_tag = len(tag_list)\n",
    "#     w_given_tag_list = [t_word for t_word, _ in tag_list if t_word == word]\n",
    "#     count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "#     return count_w_given_tag / count_tag\n",
    "\n",
    "tag_count = defaultdict(int)\n",
    "w_given_tag_count = defaultdict(int)\n",
    "\n",
    "for word, tag in flattened_list:\n",
    "    # Store tag counts in tag_count dictionary\n",
    "    tag_count[tag] += 1\n",
    "    \n",
    "    # Store word given tag count in w_given_tag_count dictionary\n",
    "    w_given_tag_count[(word, tag)] += 1\n",
    "\n",
    "for i, tag in enumerate(unique_tag_list):\n",
    "    n_tag_occurrences = tag_count[tag]\n",
    "    for j, word in enumerate(unique_word_list):\n",
    "        count_w_given_tag = w_given_tag_count[(word, tag)]\n",
    "        B[i, j] = count_w_given_tag / n_tag_occurrences\n",
    "\n",
    "# Convert B to a dataframe for better readability\n",
    "B_df = pd.DataFrame(B, columns=unique_word_list, index=unique_tag_list)\n",
    "B_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition Probability\n",
    "\n",
    "The transition probability is the probability of transitioning from state $s_i$ to state $s_j$ at any time $t$.\n",
    "\n",
    "More precisely, $P(q_{t+1}=s_j | q_t=s_i)=\\frac{Count(s_i s_j)}{Count(s_i)}$, where $q_t=$ hidden state at time $t$,\n",
    "$s_i=$ POS tag $i$.\n",
    "\n",
    "> Note that $P(tag_i | start-tag) = P(tag_i | '.')$\n",
    "\n",
    "> Note that this function takes in a list of words and its corresponding POS tags to determine the emission probability\n",
    "> for each word and tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcualte_transition_prob(t2, t1, train_data):\n",
    "    tags = [t_tag for _, t_tag in train_data]\n",
    "    count_t1 = len([t for t in tags if t == t1])\n",
    "    count_t2_t1 = 0\n",
    "\n",
    "    for i in range(len(tags) - 1):\n",
    "        if tags[i] != t1 or tags[i + 1] != t2:\n",
    "            continue\n",
    "        count_t2_t1 += 1\n",
    "\n",
    "    return count_t2_t1 / count_t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create the transition probability matrix $A$ which has a dimension of `t_len` x `t_len`, where each column\n",
    "is the new state (POS tag) that we want to transition to, and each row represent the old state (POS tag).\n",
    "\n",
    "For example, $A[i, j]$ represents $P(tag_j | tag_i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUM</th>\n",
       "      <th>DET</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>PART</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>VERB</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SYM</th>\n",
       "      <th>AUX</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>X</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PRON</th>\n",
       "      <th>ADV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.031528</td>\n",
       "      <td>0.013476</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.103738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036868</td>\n",
       "      <td>0.012713</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>0.016527</td>\n",
       "      <td>0.454361</td>\n",
       "      <td>0.151284</td>\n",
       "      <td>0.026443</td>\n",
       "      <td>0.022629</td>\n",
       "      <td>0.042715</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>0.026697</td>\n",
       "      <td>0.031274</td>\n",
       "      <td>0.016527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.016139</td>\n",
       "      <td>0.014672</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.010422</td>\n",
       "      <td>0.629869</td>\n",
       "      <td>0.006172</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.247951</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.048062</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.019781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTJ</th>\n",
       "      <td>0.027592</td>\n",
       "      <td>0.037625</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.017559</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.030100</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.023411</td>\n",
       "      <td>0.050167</td>\n",
       "      <td>0.045987</td>\n",
       "      <td>0.436455</td>\n",
       "      <td>0.004181</td>\n",
       "      <td>0.014214</td>\n",
       "      <td>0.020903</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.172241</td>\n",
       "      <td>0.030100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.030083</td>\n",
       "      <td>0.269214</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.047481</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.009818</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.013588</td>\n",
       "      <td>0.039626</td>\n",
       "      <td>0.175745</td>\n",
       "      <td>0.036288</td>\n",
       "      <td>0.002788</td>\n",
       "      <td>0.006323</td>\n",
       "      <td>0.053686</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.049366</td>\n",
       "      <td>0.236500</td>\n",
       "      <td>0.022071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPACE</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.085938</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCONJ</th>\n",
       "      <td>0.012287</td>\n",
       "      <td>0.075368</td>\n",
       "      <td>0.003967</td>\n",
       "      <td>0.021672</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.015577</td>\n",
       "      <td>0.038313</td>\n",
       "      <td>0.214977</td>\n",
       "      <td>0.116099</td>\n",
       "      <td>0.007643</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.049536</td>\n",
       "      <td>0.059598</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.030283</td>\n",
       "      <td>0.257353</td>\n",
       "      <td>0.094137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PART</th>\n",
       "      <td>0.003449</td>\n",
       "      <td>0.022416</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.011639</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>0.009592</td>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.691238</td>\n",
       "      <td>0.038043</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.076840</td>\n",
       "      <td>0.038043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006574</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.056903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCONJ</th>\n",
       "      <td>0.004927</td>\n",
       "      <td>0.068163</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.018752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.015604</td>\n",
       "      <td>0.015467</td>\n",
       "      <td>0.029565</td>\n",
       "      <td>0.041473</td>\n",
       "      <td>0.018478</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.042705</td>\n",
       "      <td>0.037777</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.015877</td>\n",
       "      <td>0.661100</td>\n",
       "      <td>0.025459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.013291</td>\n",
       "      <td>0.133240</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.192746</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.020647</td>\n",
       "      <td>0.065517</td>\n",
       "      <td>0.033101</td>\n",
       "      <td>0.024680</td>\n",
       "      <td>0.082460</td>\n",
       "      <td>0.075916</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>0.007153</td>\n",
       "      <td>0.048928</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.014788</td>\n",
       "      <td>0.227166</td>\n",
       "      <td>0.055219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.004807</td>\n",
       "      <td>0.013988</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.173096</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.080478</td>\n",
       "      <td>0.025388</td>\n",
       "      <td>0.031386</td>\n",
       "      <td>0.064148</td>\n",
       "      <td>0.109728</td>\n",
       "      <td>0.285884</td>\n",
       "      <td>0.004293</td>\n",
       "      <td>0.060369</td>\n",
       "      <td>0.014666</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.012653</td>\n",
       "      <td>0.073782</td>\n",
       "      <td>0.041862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUNCT</th>\n",
       "      <td>0.014872</td>\n",
       "      <td>0.058271</td>\n",
       "      <td>0.019954</td>\n",
       "      <td>0.032113</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.082746</td>\n",
       "      <td>0.010039</td>\n",
       "      <td>0.047765</td>\n",
       "      <td>0.091320</td>\n",
       "      <td>0.080501</td>\n",
       "      <td>0.039689</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.026501</td>\n",
       "      <td>0.046517</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>0.059207</td>\n",
       "      <td>0.300804</td>\n",
       "      <td>0.079161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYM</th>\n",
       "      <td>0.412821</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.060256</td>\n",
       "      <td>0.320513</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.055128</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.091026</td>\n",
       "      <td>0.010256</td>\n",
       "      <td>0.005128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUX</th>\n",
       "      <td>0.012373</td>\n",
       "      <td>0.088329</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.036715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.159537</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.275289</td>\n",
       "      <td>0.020302</td>\n",
       "      <td>0.018989</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.055856</td>\n",
       "      <td>0.101813</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.006818</td>\n",
       "      <td>0.074390</td>\n",
       "      <td>0.136407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.010237</td>\n",
       "      <td>0.005918</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.089891</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.042440</td>\n",
       "      <td>0.025272</td>\n",
       "      <td>0.024845</td>\n",
       "      <td>0.013329</td>\n",
       "      <td>0.509544</td>\n",
       "      <td>0.150565</td>\n",
       "      <td>0.002772</td>\n",
       "      <td>0.007358</td>\n",
       "      <td>0.047451</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.020207</td>\n",
       "      <td>0.030177</td>\n",
       "      <td>0.018607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.008715</td>\n",
       "      <td>0.026144</td>\n",
       "      <td>0.008715</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017429</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.028322</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>0.071895</td>\n",
       "      <td>0.283224</td>\n",
       "      <td>0.047930</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>0.028322</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.034858</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.030501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PROPN</th>\n",
       "      <td>0.015796</td>\n",
       "      <td>0.015687</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.058469</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.051229</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.013493</td>\n",
       "      <td>0.063624</td>\n",
       "      <td>0.110136</td>\n",
       "      <td>0.261738</td>\n",
       "      <td>0.008556</td>\n",
       "      <td>0.053861</td>\n",
       "      <td>0.016455</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.241992</td>\n",
       "      <td>0.038613</td>\n",
       "      <td>0.022159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.012206</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.046234</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.015635</td>\n",
       "      <td>0.012014</td>\n",
       "      <td>0.013669</td>\n",
       "      <td>0.280353</td>\n",
       "      <td>0.127407</td>\n",
       "      <td>0.069854</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.275413</td>\n",
       "      <td>0.034915</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>0.040095</td>\n",
       "      <td>0.062469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.014738</td>\n",
       "      <td>0.040938</td>\n",
       "      <td>0.003275</td>\n",
       "      <td>0.081291</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.027136</td>\n",
       "      <td>0.015323</td>\n",
       "      <td>0.035909</td>\n",
       "      <td>0.242880</td>\n",
       "      <td>0.018481</td>\n",
       "      <td>0.156734</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.040295</td>\n",
       "      <td>0.137143</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.007018</td>\n",
       "      <td>0.076671</td>\n",
       "      <td>0.100883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            NUM       DET      INTJ       ADP     SPACE     CCONJ      PART  \\\n",
       "NUM    0.031528  0.013476  0.000763  0.103738  0.000000  0.036868  0.012713   \n",
       "DET    0.016139  0.014672  0.000051  0.000253  0.000101  0.000051  0.000051   \n",
       "INTJ   0.027592  0.037625  0.065217  0.017559  0.000836  0.030100  0.003344   \n",
       "ADP    0.030083  0.269214  0.002160  0.047481  0.000275  0.009818  0.004202   \n",
       "SPACE  0.000000  0.046875  0.023438  0.140625  0.000000  0.007812  0.015625   \n",
       "CCONJ  0.012287  0.075368  0.003967  0.021672  0.000193  0.001258  0.015577   \n",
       "PART   0.003449  0.022416  0.000862  0.011639  0.000216  0.002371  0.009592   \n",
       "SCONJ  0.004927  0.068163  0.000684  0.018752  0.000000  0.003422  0.015604   \n",
       "VERB   0.013291  0.133240  0.002866  0.192746  0.000076  0.020647  0.065517   \n",
       "NOUN   0.004807  0.013988  0.002259  0.173096  0.000185  0.080478  0.025388   \n",
       "PUNCT  0.014872  0.058271  0.019954  0.032113  0.002089  0.082746  0.010039   \n",
       "SYM    0.412821  0.006410  0.001282  0.005128  0.000000  0.003846  0.000000   \n",
       "AUX    0.012373  0.088329  0.000758  0.036715  0.000000  0.003384  0.159537   \n",
       "ADJ    0.010237  0.005918  0.001066  0.089891  0.000160  0.042440  0.025272   \n",
       "X      0.008715  0.026144  0.008715  0.019608  0.000000  0.017429  0.004357   \n",
       "PROPN  0.015796  0.015687  0.002194  0.058469  0.001426  0.051229  0.023256   \n",
       "PRON   0.002446  0.012206  0.000552  0.046234  0.000384  0.015635  0.012014   \n",
       "ADV    0.014738  0.040938  0.003275  0.081291  0.000175  0.027136  0.015323   \n",
       "\n",
       "          SCONJ      VERB      NOUN     PUNCT       SYM       AUX       ADJ  \\\n",
       "NUM    0.009916  0.016527  0.454361  0.151284  0.026443  0.022629  0.042715   \n",
       "DET    0.000202  0.010422  0.629869  0.006172  0.001619  0.000202  0.247951   \n",
       "INTJ   0.023411  0.050167  0.045987  0.436455  0.004181  0.014214  0.020903   \n",
       "ADP    0.013588  0.039626  0.175745  0.036288  0.002788  0.006323  0.053686   \n",
       "SPACE  0.093750  0.046875  0.085938  0.054688  0.000000  0.039062  0.015625   \n",
       "CCONJ  0.038313  0.214977  0.116099  0.007643  0.001354  0.049536  0.059598   \n",
       "PART   0.006035  0.691238  0.038043  0.020800  0.000323  0.076840  0.038043   \n",
       "SCONJ  0.015467  0.029565  0.041473  0.018478  0.000411  0.042705  0.037777   \n",
       "VERB   0.033101  0.024680  0.082460  0.075916  0.001826  0.007153  0.048928   \n",
       "NOUN   0.031386  0.064148  0.109728  0.285884  0.004293  0.060369  0.014666   \n",
       "PUNCT  0.047765  0.091320  0.080501  0.039689  0.001434  0.026501  0.046517   \n",
       "SYM    0.003846  0.060256  0.320513  0.005128  0.008974  0.003846  0.055128   \n",
       "AUX    0.007979  0.275289  0.020302  0.018989  0.001010  0.055856  0.101813   \n",
       "ADJ    0.024845  0.013329  0.509544  0.150565  0.002772  0.007358  0.047451   \n",
       "X      0.028322  0.065359  0.071895  0.283224  0.047930  0.010893  0.028322   \n",
       "PROPN  0.013493  0.063624  0.110136  0.261738  0.008556  0.053861  0.016455   \n",
       "PRON   0.013669  0.280353  0.127407  0.069854  0.000695  0.275413  0.034915   \n",
       "ADV    0.035909  0.242880  0.018481  0.156734  0.000760  0.040295  0.137143   \n",
       "\n",
       "              X     PROPN      PRON       ADV  \n",
       "NUM    0.002543  0.026697  0.031274  0.016527  \n",
       "DET    0.000101  0.048062  0.004300  0.019781  \n",
       "INTJ   0.000836  0.019231  0.172241  0.030100  \n",
       "ADP    0.000785  0.049366  0.236500  0.022071  \n",
       "SPACE  0.000000  0.281250  0.117188  0.031250  \n",
       "CCONJ  0.000387  0.030283  0.257353  0.094137  \n",
       "PART   0.000000  0.006574  0.014657  0.056903  \n",
       "SCONJ  0.000137  0.015877  0.661100  0.025459  \n",
       "VERB   0.000380  0.014788  0.227166  0.055219  \n",
       "NOUN   0.001027  0.012653  0.073782  0.041862  \n",
       "PUNCT  0.006984  0.059207  0.300804  0.079161  \n",
       "SYM    0.006410  0.091026  0.010256  0.005128  \n",
       "AUX    0.000051  0.006818  0.074390  0.136407  \n",
       "ADJ    0.000160  0.020207  0.030177  0.018607  \n",
       "X      0.215686  0.034858  0.098039  0.030501  \n",
       "PROPN  0.001316  0.241992  0.038613  0.022159  \n",
       "PRON   0.000144  0.005515  0.040095  0.062469  \n",
       "ADV    0.000351  0.007018  0.076671  0.100883  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.zeros((t_len, t_len))\n",
    "for i, t1 in enumerate(list(all_tags)):\n",
    "    for j, t2 in enumerate(list(all_tags)):\n",
    "        A[i, j] = calcualte_transition_prob(t2, t1, flattened_list)\n",
    "\n",
    "# Convert A to a dataframe for better readability\n",
    "A_df = pd.DataFrame(A, columns = list(all_tags), index=list(all_tags))\n",
    "A_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi Algorithm\n",
    "\n",
    "Now that we have already prepared our initial state matrix, $\\pi$, transition probability matrix, $A$ and our emission\n",
    "probability matrix, $B$, we have our model ready to be used with Viterbi algorithm, which uses dynamic programming, to\n",
    "perform POS tagging based on $\\pi$, $A$ and $B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(words, pos_tags, A, B, pi, default_prob=1e-5):\n",
    "    T = len(words)\n",
    "    N = len(pos_tags)\n",
    "    \n",
    "    # Initialize the Viterbi matrix and backtrack matrix\n",
    "    viterbi_matrix = np.zeros((N, T))\n",
    "    backtrack_matrix = np.zeros((N, T), dtype=int)\n",
    "    \n",
    "    # Initialisation step\n",
    "    for s, pos_tag in enumerate(pos_tags):\n",
    "        viterbi_matrix[s, 0] = pi.loc[0, pos_tag] * (B.loc[pos_tag, words[0]] if words[0] in B.columns else default_prob)\n",
    "        backtrack_matrix[s, 0] = 0\n",
    "    \n",
    "    # Recursion step\n",
    "    for t in range(1, T):\n",
    "        for s, pos_tag in enumerate(pos_tags):\n",
    "            prob_transitions = viterbi_matrix[:, t-1] * A.loc[:, pos_tag]\n",
    "            max_prob = np.max(prob_transitions)\n",
    "            observed_emission_prob = B.loc[pos_tag, words[t]] if words[t] in B.columns else default_prob\n",
    "            viterbi_matrix[s, t] = max_prob * observed_emission_prob\n",
    "            backtrack_matrix[s, t] = np.argmax(prob_transitions)\n",
    "    \n",
    "    # Termination step\n",
    "    best_path_prob = np.max(viterbi_matrix[:, -1])\n",
    "    best_last_state = np.argmax(viterbi_matrix[:, -1])\n",
    "    best_path = [pos_tags[best_last_state]]\n",
    "    \n",
    "    # Backtracking to find the best path\n",
    "    for t in range(T-1, 0, -1):\n",
    "        best_last_state = backtrack_matrix[best_last_state, t]\n",
    "        best_path.insert(0, pos_tags[best_last_state])\n",
    "    \n",
    "    return best_path, best_path_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform POS Tagging\n",
    "\n",
    "Let's have a few test examples, and perform POS tagging on each of these sequences of words via our Viterbi algorithm\n",
    "trained with our corpus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===\n",
      "Sentence: How are you doing?\n",
      "[('how', 'SCONJ'), ('are', 'AUX'), ('you', 'PRON'), ('doing', 'VERB'), ('?', 'PUNCT')]\n",
      "Probability: 6.336674775742297e-13\n",
      "===\n",
      "Sentence: In Singapore, the weather is very hot!\n",
      "[('in', 'ADP'), ('singapore', 'NOUN'), (',', 'PUNCT'), ('the', 'DET'), ('weather', 'NOUN'), ('is', 'AUX'), ('very', 'ADV'), ('hot', 'ADJ'), ('!', 'PUNCT')]\n",
      "Probability: 3.9933143519406957e-26\n",
      "===\n",
      "Sentence: What do you mean by that?\n",
      "[('what', 'PRON'), ('do', 'AUX'), ('you', 'PRON'), ('mean', 'VERB'), ('by', 'ADP'), ('that', 'PRON'), ('?', 'PUNCT')]\n",
      "Probability: 1.993599052426198e-16\n",
      "===\n",
      "Sentence: How do you tell between a cat and a dog?\n",
      "[('how', 'SCONJ'), ('do', 'AUX'), ('you', 'PRON'), ('tell', 'VERB'), ('between', 'ADP'), ('a', 'DET'), ('cat', 'NOUN'), ('and', 'CCONJ'), ('a', 'DET'), ('dog', 'NOUN'), ('?', 'PUNCT')]\n",
      "Probability: 1.1664686811587063e-25\n",
      "===\n",
      "Sentence: HS2914 is very interesting and I love it!\n",
      "[('hs2914', 'PRON'), ('is', 'AUX'), ('very', 'ADV'), ('interesting', 'ADJ'), ('and', 'CCONJ'), ('i', 'PRON'), ('love', 'VERB'), ('it', 'PRON'), ('!', 'PUNCT')]\n",
      "Probability: 9.078365864792514e-24\n"
     ]
    }
   ],
   "source": [
    "# Test examples\n",
    "test_cases = [\n",
    "    \"How are you doing?\",\n",
    "    \"In Singapore, the weather is very hot!\",\n",
    "    \"What do you mean by that?\",\n",
    "    \"How do you tell between a cat and a dog?\",\n",
    "    \"HS2914 is very interesting and I love it!\"\n",
    "]\n",
    "\n",
    "for sentence in test_cases:\n",
    "    # Normalise sentence\n",
    "    sentence_norm = sentence.lower()\n",
    "    doc = nlp(sentence_norm)\n",
    "\n",
    "    # Tokenise sentence\n",
    "    tokens = [token.text for token in doc]\n",
    "\n",
    "    # Run viterbi on the tokens\n",
    "    pos_tags, probability = viterbi(tokens, unique_tag_list, A_df, B_df, pi_df)\n",
    "\n",
    "    print(\"===\")\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(list(zip(tokens, pos_tags)))\n",
    "    print(f\"Probability: {probability}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
